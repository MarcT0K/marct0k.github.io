[{"content":"With the repeated crazy moves and statements from Musk, there are periodic emigration waves from Twitter/X. While people want to leave Twitter/X, there is always a key question to answer: where to go? This question is a valuable opportunity for Tech companies to argue endlessly in the void. In particular, Mastodon and Bluesky advocates are investing this battlefield.\nI must admit that I am quite uncomfortable with the current Mastodon-vs-Bluesky debates. I am an engineer and research working on decentralized systems. Thus, any option sounds good on paper. However, my background (especially my activist background) makes me a natural Mastodon advocate. However, I am not blind. I know that Mastodon is not ready. I can recognize that Bluesky got some elements right, even though I have major concerns about its organization.\nThis debate required nuanced arguments. Unfortunately, advocates in this debate can often be excessive and close-minded. On the one side, we have OSS engineers advocating for Mastodon while ignoring all its issues making it unsuitable for a broad audience. On the other hand, we have mainstream media praising Bluesky as the perfect alternative to Twitter/X, while not questioning whether it could become like Twitter/X.\nMy point is simple: none of these social media are the future of healthy social media (yet). On the one hand, Mastodon offers a real decentralization, but requires clear improvements to attract a broad audience. On the other hand, Bluesky is able to attract a broad audience but its organization does not guarantee a healthy social media.\nRecently, I\u0026rsquo;ve often been asked my POV on this debate. It is always hard to answer with structured and clear arguments. This post is then my answer to this tricky question. More than just answering it, I also highlight what is needed to build a healthy Social Web.\nMastodon has issues, I know To start this discussion, I feel like a criticism of Mastodon is a nice starting point. I am some sort of Mastodon enthusiasts, but I am aware of its current flaws.\nOnbooardbing issues The most obvious of Mastodon is for sure its onboarding. Any non-tech user would be lost during its first steps in Mastodon.\nMastodon advocates rightfully remind that its architecture is similar to the email system. While it is a fair point, we must remember that all other digital systems used by average Internet users are highly centralized. Even the email system is semi-centralized: most people use GMail, Outlook, or Apple depending on their operating system (Android, Windows, or iOS/MacOS).\nThus, the decentralized architecture with a mandatory sever choice is rather unsettling for most users. We then must communicate to make the decentralization accessible or even seamless.\nAs a \u0026ldquo;cryptographer\u0026rdquo;, I am quite impressed by Signal success: while cryptography was only for Tech experts in the past, Signal enable anyone to use cryptography\u0026hellip; without even knowing what it means. Tech advocates should be aware that average users do not have the time (or the knowledge) to understand the protocols. Hence, open protocols are essential but they are not a selling point for them. We must make these nice technical properties accessible.\nAn ecosystem under development This accessibility point leads me to a key element: Mastodon (and the rest of ActivityPub-based social media) is still under development. Accessibility is one part, but the community is also figuring out content moderation and many other things. A lot of amazing efforts are being pushed by organizations such as the Social Web Foundation or IFTAS.\nWe should promote what the Social Web could become, not what it currently is. It is flawed and it is all fine. Considering the negligible funds invested into ActivityPub-based social media, I am already amazed of the quality. This should be a selling point for public funders: look what these engineers are capable of with no money, imagine what they could do with even a small investment!\nMy biggest fear: a premature migration All these problems in the Fediverse created a concern within me: a premature migration. I believe the Fediverse (i.e., the ActivityPub-based social media) is a great framework for the future of social media. However, it is not ready to greet billions of Internet users. If a migration to the Fediverse happens too early, this place will explode and this ideal will have no second chance.\nMy dream would be to call for a migration when the Fediverse is ready. Such perspectives should help building the Fediverse with a clear goal. It should also force developers/administrators/users to see the current problems as a roadmap instead of a shame.\nBut Bluesky isn\u0026rsquo;t a real solution either Now, let\u0026rsquo;s talk about Bluesky. It is a clearly nice place, much nicer than Twitter/X. However, I have major concerns about it. While the founders claim it cannot become like Twitter/X, I have a few elements creating doubts.\nDecentralization washing First, there is obviously the decentralization. You can find many Mastodon advocates dissecting its pseudo-decentraliztion, so I won\u0026rsquo;t do it. In short, Bluesky protocol decentralizes some features, but not all of them (e.g., the identity management). Moreover, Bluesky has enforced many policies to prevent a really decentralization (e.g., only servers with tiny userbase can connect to Bluesky). All these elements created one clear thing: Bluesky is a decentralized social media with a single server. In comparison the Fediverse has currently nearly 30K servers; this is real decentralization.\nI read multiple times that Bluesky is \u0026ldquo;billionaire-proof\u0026rdquo; because it can be redeployed if ever a billionaire tries to take over. Indeed, Bluesky publishes most of its code in open-source. Open-source is important, but it is no longer sufficient in the Tech regulation. Big Tech companies are the many contributors to open-source (think about Microsoft with GitHub). Thus, we need more than just an open-source system. Big Tech companies manage to keep their audience captive, because massive user migration is hard to trigger (see Twitter/X). Thus, being able to redeploy a social media does not prevent this social media from keeping millions of people in its toxic environment.\nWhat is missing then? An open governence. I am not satisfied by the semi-centralized architecture of Bluesky, but it also facilitates some operations. Thus, it could be acceptable. For example, Wikipedia is centralized and nobody can contest its success. However, to make such a system a success, you need an open governance. I cannot trust a company based in the US to handle properly my digital space. Thus, if your technology is semi-centralized, decentralize at least the governance.\nWhat about the \u0026ldquo;Nazi problem\u0026rdquo;? To judge the governance of a system, I think the \u0026ldquo;Nazi problem\u0026rdquo; is the best manner. The \u0026ldquo;Nazi problem\u0026rdquo; could be formulated as follows: you leave in a peacefully digital place with like-minded people, and suddenly, a nazi arrives. What happens? Do you ban the Nazi? Do you isolate them? Do you let them talk?\nFediverse has some clear and decentralized answers. For example, the now independent social media Gab started as a Mastodon server. Since Gab was populated by toxic far-right activists, all the other Mastodon servers blocked the server and isolated these far-right activists.\nI really wonder how it would happen in Bluesky. For now, Bluesky is populated by a lot of journalists and left-leaning people. The population (like in Mastodon) is quite uniform. However, how would they deal with massive arrivals of far-right activists? More generally, how do they handle harmful content? Considering the semi-centralized architecture of Bluesky, I feel like they have to handle (at least partially) the moderation centrally. For example, they need to remove illegal content such as CSAM.\nThis semi-centralized governance is more efficient than Mastodon\u0026rsquo;s governance, but it has a drawback: who decides what is illegal? What if the governance in 5 years decides that it is unacceptable to talk about politics? I am really not a Bluesky expert, and I am sure that they provide some safeguards. However, their semi-centralized architecture must enable some centralized censorship if needed. The sole existence of such things is toxic for social media used all across the globe. As what we have seen in Big Tech social media, they could impose US social norms.\nBe careful, I don\u0026rsquo;t ask for a social media respecting EU social normsâ€¦ it would be similarly problematic. I ask for a social media where every one can have a digital space respecting its personal social norms. This is one of the main selling point of Mastodon: each server has its own editorial/moderation rules. There is no central actor to corrupt to influence the whole Mastodon network.\nA problematic absence of business model Finally, all this Bluesky phenomenon looks like a \u0026ldquo;decentralization\u0026rdquo; washing for me: it sounds nice, even if they do not really do it. I believe the founders have good intentions, but they are supported by venture capitalists whose intentions are clear: profits. Bluesky could simply be a novel manner to make surveillance capitalism acceptable. As long as they do not find a healthy business model, I will not believe that they can be the future of healthy social media.\nThey have no real source of income. One day or another, the VCs will ask for profit and force the necessary changes. The fact that Bluesky is not fully decentralized looks like a way to keep control on the network\u0026hellip; and to make profit from it, if needed. On the contrary, the low investments of VCs in the Fediverse (despite its 10M users and 30K servers) is a sign that the Fediverse could be \u0026ldquo;surveillance-capitalism-proof\u0026rdquo;.\nSocial media is MUCH MORE than microblogging Now that I have listed all the problems of both competitors, I can tell you the most important: the debate Mastodon vs. Bluesky does not matter. Microblogging is only a small part of social media (https://sproutsocial.com/insights/new-social-media-demographics/). The Twitter user base is ridiculous compared to Youtube or Tik Tok. I know that many people hate Musk (as I do), but Twitter/X should not be our only priority.\nInstagram, YouTube and TikTok are more popular (especially among young users) and have massive impact on their mental health. This debate centered on Twitter alternative is quite egotistic. Indeed, all the advocates and journalists debating this subject use essentially Twitter/X in their daily life. Twitter/X is clearly a network used mostly by journalists and politicians. Thus, all these people only discuss this matter when it comes to recreating social media.\nThis focus on Twitter/X is then a problem. Most people spend their time on YouTube/Instagram/TikTok. The outcome of this Mastodon vs. Bluesky debate is worthless. We need to look beyond it. In this context, the Fediverse has a clear headstart compared to Bluesky. Indeed, the Fediverse is much more than Mastodon: it is also Peertube (alternative to Youtube), PixelFed (alternative to Instagram), Lemmy (alternative to Reddit), Loops (alternative to TikTok), etc.\nIn short, even if Musk is crazy, we must remember that mainstream social media are problematic even without him. Surveillance capitalism is poisoning our digital world, and our real lives. We must reinvent the Web and Mastodon/Bluesky could at best be a small part of it.\nThe path to a healthy social web Until now, my post could have been quite depressing. However, I want to end on a positive note. All the previous paragraphs aimed to put everything into perspective. The Internet can be rebuild in a healthy manner but we must stop listening to VC-backed narratives. To build a Social Web, I would have three main suggestions.\nAsk for an open and decentralized governance As mentioned for Bluesky, an open and decentralized governance is absolutely necessary. The Internet is more than a tool; it is a digital world we live in. Thus, I want more than just \u0026ldquo;regulating\u0026rdquo; the Internet, I want the people to \u0026ldquo;govern\u0026rdquo; the Internet. Citizens and politicians should reconsider their relationship to the digital world. It deserves more democracy. We are much more than users: we are Internet citizens.\nEach Internet citizen has its own culture and values. The Social Web should enable all values and cultures to exist. Up until now, mainstream social media has also been a soft-power tool that pushed US social norms. Decentralization is the occasion to give a real digital home to all Internet citizens.\nBe realistic in our expectations We cannot expect 3 engineers programming during their weekends to provide a system replacing billion-dollar companies. It is unfair and it insults their work. We should acknowledge their amazing results with so small resources. We should consider their current product as a reason to finally fund their work.\nNaively comparing the product of volunteer engineers (Mastodon, Pixelfed, Lemmu) to those of VC-backed companies (Bluesky) is unfair. Journalists and editorialists should take into account the massive resource gap in their comparison.\nMore generally, we should be realistic in our expectations. Rebuilding the Internet is an ambitious project that cannot succeed in one or two years thanks to three part-time volunteer engineers. Rebuilding the Internet will require investment, and we must be aware of it. Big Tech made us believe that it could be for free\u0026hellip; it was not. The cost has been our personal lives, our mental health, and our democratic stability.\nFind a business model for the Social Web Finally, the Social Web desperately need one thing: a business model. While I am vocal against surveillance capitalism, we have to propose a viable and healthy business model. Fediverse (and Bluesky) advocates are quite silent on the matter. It is a big mistake according to me. Leaving uncertainty will leave opportunities for the surveillance capitalism to come back.\nThus, I brainstormed various ideas and have a suggestion: public subventions. I would take inspiration from the French newspaper: each newspaper receives a state subvention proportional to its number of readers. We could do the same for social media: each server would receive a subvention based on its number of users. This subvention is not supposed to cover all operational costs. Each French newspaper has to complement its revenues with ads, subscriptions, or anything else. Servers in the Social Web could do the same: they could provide some ads or subscription to complete their revenues. This business model would inject money into alternative social media and structure the public investment in our digital space.\nHowever, this model is more suitable with the Fediverse than with Bluesky. The semi-centralization of Bluesky would complicate public subventions because the states (other than the US) would be reluctant to fund a US-based company. The real decentralization of Mastodon (and the whole Fediverse) would give the opportunity to any state to fund servers only based in their countries: France would support French organizations, the Netherlands would support Dutch organizations, India would support Indian organizations, etc. Thanks to the ActivityPub protocol, all servers would still be interconnected, we would have a global social media, but each country would be able to fund and regulate their share of the digital world.\n","permalink":"https://marc.damie.eu/posts/mastodon-vs-bluesky/","summary":"With the increasing issues in Twitter/X governance, there is a recurring debate within Tech communities: is Mastodon or Bluesky the future? According to me, none of them.","title":"Mastodon vs. Bluesky, the future of healthy social media is not there (yet)"},{"content":"As every few years, the ACM Conference on Computer and Communications Security (a.k.a. \u0026ldquo;CCS\u0026rdquo;) was organized in Europe. This time, the city of Copenhagen had the burden privilege of greetings security researchers from all over the world. For the occasion, the security group of the University of Twente organized a collective trip to CCS.\nThe organization The trip My trip was paid by Inria, so I had some freedom regarding transportation. Anyway, for environmental reasons, I decided to take the train. The rest of the group also took the train\u0026hellip; but the University of Twente hadn\u0026rsquo;t given them the choice. Hence, we went all together on a 9-hour train ride to Copenhagen with 2 connections. From my perspective, 9â€“10 hours seems the maximum train trip I would do to go to a conference. If the train travel time exceeds 10 hours, I think I would go by plane. Indeed, 10 hours already requires a full day to travel and it can get much longer if any of the trains is delayed.\nThis observation raises many questions regarding how researchers should reduce their carbon footprint. In computer science, travels to attend conference represent a major part of carbon emissions. The choice of a conference location is then a key leverage to minimize carbon footprint. Unfortunately, most conferences happen in the US. Even if the US host a significant part of the scientific community, I believe this choice does not minimize the carbon footprint. Interestingly, some researchers calculated the carbon footprint of AI conferences and estimated the same footprint if they had been organized somewhere else: http://arxiv.org/abs/2311.14692. Apparently, Central Europe or China are the best locations if we want to minimize carbon footprint. I hope security conference will take this into account in the future. However, I am also aware that this practice could limit the diversity of destinations. Anyway, most security conferences are only organized in the US, so this diversity argument sounds a bit weak right now.\nThe venue The trip was a bit long, but we finally arrived in Copenhagen and were able to enjoy the conference. The congress center seemed ideal for such an event: neither too big nor too small. It was located next to many hostels, so we could book affordable rooms easily. There was plenty of food, coffee, and tea to occupy the breaks. While I had rather low expectations for food, I must admit the quality was nice.\nOverall, I want to congratulate the organizers and all the people who contributed to the organization. Everything went smoothly.\nEven if the overall experience was great, I must talk publicly about one detail, so the Internet won\u0026rsquo;t forget about it: the program interface. The program was available on the website and it has been one of the worst Web UI experiences I\u0026rsquo;ve ever had. I discussed it with other colleagues and there was a perfect common agreement. The navigation was so bad that someone implemented a pure HTML website, much easier to navigate! Anyway, this detail did not prevent me from enjoying the talks ðŸ™ƒ.\nDiscovering the security research community My first security conference\u0026hellip; but my second scientific conference Even though I already have two published papers, CCS was my first security conference. Unfortunately, I published my first USENIX paper during the \u0026ldquo;COVID years\u0026rdquo;, so the conference was remote. CCS was then my first broad contact with the security research community. However, my presence in this conference felt very naturally. One year ago, I had attended an ML conference and I felt totally overwhelmed by the conference and the scientific content. The conference size was similar, but I felt much more lost in the ML conference.\nI don\u0026rsquo;t know for sure why it felt so natural in CCS; but I may have a couple of ideas. First, I now have more experience. Over the last year, I attended multiple scientific events, especially in the security field. During CCS, I even talked to researchers I had met during these events! Hence, I am now more prepared for large conferences and their flow of presentations. Second, I consider myself a privacy researcher. My initial training is in ML, but I don\u0026rsquo;t intend to make ML the center of my future research. In the context of my Ph.D., ML provides interesting problems to solve, but I hope my future career will have a larger scope. Therefore, the presentations I saw at CCS are much closer to my pure research interests than what I saw at ECML-PKDD.\nSome open debates Besides the talks, the program was marked by two interesting events: the 30th anniversary and the \u0026ldquo;CCS business meeting.\u0026rdquo; On the one hand, for the 30th anniversary, the first ever CCS chair presented a brief retrospective of CCS from the first edition with 25 attendees to the 1K attendees we have nowadays. This presentation was a great occasion to understand how top conferences started. After this presentation, there was a panel discussion to debate about various questions related to CCS such as diversity, reviewing process, and the future of the conference. On the other hand, the business meeting was a general assembly of ACM SIGSAC. The chair presented the current situation of SIGSAC and discussed the future directions. In both events, I appreciated the open discussions. These events could be common among scientific communities. However, this was a happy discovery for me. Scientific communities are rather obscure organizations; only researchers know about them. This hidden self-organization may lead to many issues, but this transparency seems to be the sign of a healthy organization.\nOne may argue that it is not perfectly open, since only the people present in the room can take part in the discussion. Anyway, who would watch a livestream of a CCS business meeting? ðŸ˜…\nIs it healthier than the ML community? Finally, my previous post about ECML-PKDD was extremely critical of the ML community. I do not redevelop everything here, but the security community shares many of these issues. Presentations are not very accessible because they are overly specialized. The capitalistic interests are less obvious, but I believe they are also present (a bit developed in the next section). More generally, all scientific communities share these problems. However, I believe some aspects are better in the security community than in the ML community.\nThe ML community is getting enormous, which creates an unhealthy competition between researchers. Everyone is in the hurry of publishing papers because everyone fears that someone else will publish their idea first. The ML literature simply looks like an unstoppable flow of noisy information. There are always multiple concurrent works, so it is difficult to keep track of recent advances. Up to now, the security community is still small enough, so one can follow the latest discoveries. For example, everyday I read the ArXiv RSS feed of security papers. I can read all the titles and skim through the abstracts. However, I cannot do the same for the ML RSS feed because there are too many papers posted every day. For ML papers, I need to filter the papers based on some keywords.\nThis size issue is also visible in the reviewing process. The ML reviewing process seems rather random as they are so many papers to review. Top ML conference have program committees composed of thousands of researchers. Such program committees cannot enforce clear standards, as it is the case in security. Hence, I believe the security community is for now healthier.\nMy regrets/hopes My previous paragraphs put a positive light on security research. However, I still have some concerns/regrets/hopes. As mentioned before, the community seems healthy, but there are multiple possible improvements.\nA community fighting unnamed attackers My main critic is regarding the security motivations. A thousand researchers spent a week talking about security weaknesses and attack defenses, but I\u0026rsquo;ve not heard the name of a potential attacker. We are a community spending hours defending against anonymous attackers. This observation is a clear symptom of the \u0026ldquo;apolitical\u0026rdquo; stand wanted by many researchers. I believe we should name the organizations behind the threats. Often, we hear about a vague \u0026ldquo;hacker\u0026rdquo;. However, many recent large-scale attacks have been orchestrated by national security agencies from China, Russia, the US, or anywhere else in the world (even the European Union).\nWhile state agencies seem to be an essential adversary for system or network security, Big Tech companies are the main threat for privacy. However, privacy researchers rarely name Google, Microsoft, or TikTok as a privacy threat. Many research directions even try to make these systems \u0026ldquo;privacy-preserving\u0026rdquo;\u0026hellip; even though these companies\u0026rsquo; business model is based on personal data. Hence, these privacy research lines clearly have some \u0026ldquo;hidden\u0026rdquo; capitalistic interests. I would appreciate more open and political discussions about the alternatives.\nMore generally, I would like to see more researchers talking concretely about the threats. Cybersecurity is considered a strategic sector in all modern democracies. It feels a bit nonsensical to act as if our research is purely apolitical. Obviously, it may lead to conflict as attendees are funded by different countries, with possibly orthogonal political interests. It could be the occasion to think about our contradictions as a community; e.g., accepting money from Big Tech companies in privacy/security conferences while they don\u0026rsquo;t comply with privacy laws. Within Western societies, the average citizen\u0026rsquo;s trust in science is decreasing. I believe these contradictions contribute to some mistrust.\nTo sum up, cybersecurity and privacy are two highly political issues. Security conferences should have open debates (e.g., via targeted keynotes) to understand the shortcomings of our research works. The goal is not to create conflicts between the participants. My goal is to take a step back and understand whether some lines of work fail at solving the real-world security and privacy issues.\nThe need for alternative publication formats My second concern is the publication venues. As many computer science sub-fields, computer security researchers essentially publish in conference. This habit leads to weird situations where researchers may like to present remotely in conferences\u0026hellip; which makes the conferences far less interesting since we can no longer meet the authors. The motivations for these remote presentations are diverse: from visa issues to a lack of time/interest. In any case, the absence of alternative to security conferences for good research papers is an issue. Some fields such as ML have multiple high-quality journals. Security research should also have high-quality journals, so we have a choice between journal and conferences depending on our personal constraints.\nDuring CCS 30th anniversary, all the panel participants agreed that ACM TOPS was now an excellent journal to publish security papers. This common agreement is great news, but we may need a couple of other recognized journals. Moreover, as a community, we should also pay more attention to these journal papers, so they become as visible as conference papers.\nScalability of the reviewing process Finally, the 30th anniversary panel discussion was also the occasion to sketch the future of CCS. According to the chairs\u0026rsquo; estimation, the conference size should double within a few years. Everything would be doubled: the number of attendees, the number of submissions, and the number of papers. The panel tried to be reassuring about our capacity (as a community) to scale. ML was taken as an example as they managed to scale much higher. However, I believe the panel participants were too optimistic. Everyone in ML complains about the quality of the review process. Hence, the security community should soon learn from the issues identified in the ML community before the community gets too large. Even if I have no certainty, I feel like changing significantly the reviewing process would become challenging once the community is much larger. Unfortunately, I am still a young Ph.D. student, so I won\u0026rsquo;t be able to play a significant role in the upcoming changes. I simply hope the community manages to scale while maintaining the same quality standard.\nConclusion This is the end of this new episode of my conference diary. This post was a bit less structured than previous posts. My goal was simply to present my naive first thoughts about the conference and the community. Despite my few concerns, I appreciated a lot the conference. This event helped me make a first step into the security community. Moreover, I believe my criticism is an essential part of my early research career. These PhD years are an ideal moment to understand how the scientific world works and what could be my place there. I also try to see these concerns in a more positive way: my future contribution within our community could be to fix these elements I perceive as issues.\nAnyway, CCS was a great experience and I hope I will soon have a paper published there to meet the security community again.\n","permalink":"https://marc.damie.eu/posts/ccs-23/","summary":"In November 2023, I attended my first security conference: CCS 2023. So, how was it?","title":"CCS 2023, my first security conference"},{"content":"Recently, I was watching random Youtube videos late in the evening when suddenly\u0026hellip; an ad about Samsung KNOX appeared. As a security researcher, this name instantly rang a bell but I was not expecting at all to see an ad about it.\nSamsung KNOX is a new hardware implementing a \u0026ldquo;Trusted Execution Environment\u0026rdquo; (TEE). TEE is a hot topic in security to solve many privacy issues but I always considered it as an expert debate. Obviously, this ad presented this technology in a very appealing (and non-informative) way. More generally, many scientific and non-scientific papers promote TEE as a key component for future privacy-enhancing technologies (PET).\nWhen I discuss informally with security researchers, this point of view is not shared by the whole community. Some researchers (including myself) have some concerns about this technology. However, I have never read structured criticism. This post will humbly put some words on my concerns regarding TEE.\nBefore starting this discussion, a little disclaimer is necessary: I work on PETs but I am not a TEE expert. From time to time, I read about TEE-based solutions which can be a direct alternative to my own solutions. Hence, I have a high-level understanding of TEE. I may make some mistakes about the implementation details so I will try to be extra careful.\nWhat is TEE? TEE is a hardware technology also referred to as secure enclaves or secure hardware. As presented in the schema, TEE is an isolated section of the CPU with a dedicated OS. This technology guarantees that anything happening in the TEE remains private. Even the CPU owner cannot read what is going on in this part of the CPU! The only counterpart to this strong guarantee is that we need to trust the CPU manufacturer. For more information about TEE, please refer to the dedicated Wikipedia page.\nThis security guarantee sounds marvelous because it may solve more or less any privacy issue: an organization can process private data without being able to read it in the clear. We don\u0026rsquo;t need to trust private companies to respect our data privacy since TEE ensures they cannot even access it. However, I believe there are some downsides that we need to discuss before investing too much effort into this technology.\nSeveral major chip manufacturers already implemented TEE: Intel SGX, Samsung KNOX, ARM TrustZone, etc.\nA trust issue The first issue is the trust assumption. Often, we could be a bit breezy about this point. Indeed, the security holds as long as we trust the chip manufacturer to not leak some sort of master cryptographic key. This is not a trivial assumption.\nOver the last decades, we had several examples of companies sharing private data with national security agencies. It has been a key enabler for mass surveillance. Hence, trusting such companies could be unsatisfying for many use cases, especially for activists whose lives depend on the security of their communications.\nLet\u0026rsquo;s assume we consider only economical/mainstream use cases. Thus, trusting a chip manufacturer could be acceptable. I argue there remains another implicit trust assumption: we need to trust the developers. As highlighted in the schema, the application and the OS are also trusted. Any flaw in the implementation could lead to a privacy breach. More generally, the TEE literature has described many side-channel attacks breaking the security of some so-called secure algorithms.\nWhile software vulnerabilities are not specific to TEE, I believe this technology increases the attack surface. In classic cryptography, we usually have reference implementations subject to many audits (e.g., OpenSSL). In TEE, the hardware and the associated OS are (for now) all proprietary, so many unknown vulnerabilities might be present. While closed-source cryptography is now seen as a red flag in security, I am afraid TEE could go back in time and reintroduce some closed-source security solutions.\nMoreover, the side-channel attacks in TEE are subtle and we would need some complex frameworks to check that app developers do not break the security with insecure operations.\nA silver bullet TEE is often presented as a silver bullet. Indeed, in theory, TEE is a perfect solution to many (nay all?) privacy issues. This silver-bullet discourse is my second concern.\nDon\u0026rsquo;t get me wrong, I am not conservative about my research. If needed, I don\u0026rsquo;t mind switching to other primitives when it makes sense. However, I believe security and privacy are complex issues and we must be careful when coping with them. When someone talks about a form of universal solution I am always a bit skeptical: it always sounds too good to be true.\nMy message is just to be careful with TEE. I believe it will solve some privacy issues\u0026hellip; but not all issues. Hence, we must remain clear about the advantages and disadvantages of this technology, and avoid getting hyped by a nice-looking solution heavily promoted by private interests. Indeed, don\u0026rsquo;t forget that powerful companies have a major economical interest in this technology\u0026hellip; they could make big money if TEE becomes the pivotal element of any secure system.\nA proprietary solution A previous paragraph already discussed the security risk induced by closed sources. Proprietary solutions also raise some societal issues: our security would be somehow owned by a private company. To understand this point, we can compare TEE to classic cryptographic libraries. If the OpenSSL foundation closes, anyone can fork the project and maintain the implementations. If Intel suddenly closes, I doubt we could maintain the OS or produce new chips.\nAn underlying problem here is interoperability. Each manufacturer produces their own TEE and I haven\u0026rsquo;t seen any attempt of interoperability. This is a new market so all manufacturers may try to obtain as many market shares as possible and they have low incentives to make everything interoperable. However, the use cases of TEE are not yet well-established so it could be a bit too early for a unique standard. Still, we should be aware of the long-term risks associated with these techniques.\nEven an open-source standard, TEE remains a proprietary solution. It is a hardware-based solution, so our security relies on a handful of private companies. In other words, with TEE, the PETs would inherit the centralization problems present in the hardware industry.\nObsolescence I want to end this post with an overlooked issue: obsolescence. If we switch to hardware-based solutions, we would need to replace many functional devices with new devices compatible with TEE. Obsolescence isn\u0026rsquo;t specific to TEE but TEE is clearly yet another reason to buy new hardware. Once again, all chip manufacturers have a strong economical interest in this technology. We must remember their priority is not to sell us privacy, they sell us hardware\u0026hellip;\nObsolescence would be a long-term issue: it remains present even for devices with integrated TEE. The secure hardware is always linked to a secure OS. Hence, the life expectancy of our hardware will be correlated to the software maintenance provided by the manufacturer. While several Linux distributions support old hardware, I doubt we will have open-source distributions for old TEE.\nInformation Technologies (IT) like any other modern technology have to find a sustainable model. Privacy should not be seen as a reason to excuse any form of waste. Recent studies on IT sustainability all showed that hardware production is the first source of carbon emissions in IT. Therefore, reducing hardware production should be our first goal with it comes to IT sustainability\u0026hellip; and TEE production is not in line with this goal.\nMost security researchers only develop some software, but software has a very concrete impact on the environment.\nConclusion I hope this post gave you a new perspective on TEE. It is a hot topic in security and a contradictory debate is always interesting. My post could seem a bit too negative, but I still admit that TEE has many advantages. I am convinced you can find many papers/articles selling the promises of TEE. I intended to give some light on the untold downsides of this technology.\n","permalink":"https://marc.damie.eu/posts/tee-discussion/","summary":"In this post, I want to give my thoughts about a hot topic in privacy-enhancing technologies: Trusted Execution Environments.","title":"My concerns about Trusted Execution Environment"},{"content":"Every year, French privacy researchers gather around June to present their last results at APVP (Atelier sur la Protection de la Vie PrivÃ©e). It is a scientifically rich event with contributions from various areas, including machine learning, network security, and web browsing.\nFirst and foremost, I want to thank Jean-FranÃ§ois Couchot. Everything was well organized, from the talks to the \u0026ldquo;extra-academic\u0026rdquo; activities.\nThe venue The intent of APVP is to be organized everywhere in different places in France. However, there is a condition: it must be in the middle of nowhere. This year, the organization committee chose Arc-et-Senans, specifically the \u0026ldquo;Saline Royale\u0026rdquo; (a historical building). It is a gorgeous place where we can sleep, work and eat. The rooms are super comfortable, the building has multiple beautiful gardens, and the food is great. We had fantastic weather, so we could walk around the gardens to relax and enjoy the starry sky during the night. And the cherry on the cake: the venue is next to the train station! I cannot wait to return to the Saline Royale for another scientific event.\nThe community Since none of my PhD advisors are French, it was the occasion to create some links with the French-speaking community. We were about 30 attendees, which was the perfect size from my point of view. I do not know whether this could lead to collaboration, but I believe having structured privacy communities is crucial. Hence, this event is great for maintaining such a structure.\nI particularly appreciated the presence of researchers from French agencies. It is nice to see that our work can influence public policies.\nThe talks Contrary to the ESSA workshop I attended the week before, I cannot draw a general conclusion from the talks. Indeed, the goal was to gather several privacy-related communities, so the research directions were very diverse. Still, I enjoyed discovering new topics. I particularly remember the talks about web browsing, probably because anyone in the room is concerned by the results.\nMy talk Finally, I should say a few words about my presentation. I presented an ongoing work about sparse matrix multiplication. With my PhD advisors, we conceived and implemented secure algorithms for sparse matrix multiplications. We started with naive algorithms, and they already provide significant runtime reduction. They also enable some real-world applications not supported by state-of-the-art methods.\nThe paper should be submitted within a few months, and a preprint will come soon.\nWhat\u0026rsquo;s next? Unfortunately, the talks would not help me to conjecture the future of privacy research. I feel like the community is still overwhelmed by GDPR and its consequences. The community (including my work) is providing solutions to comply with GDPR, but there is no vision of the next step after GDPR. I would be interested in some debates about mass surveillance or surveillance capitalism\u0026hellip; it would be for another time!\n","permalink":"https://marc.damie.eu/posts/apvp-23/","summary":"After the ESSA workshop, I continued my \u003cdel\u003eholidays\u003c/del\u003e professional travels with APVP 2023","title":"APVP, the annual gathering of French privacy researchers"},{"content":"ESSA (Encryption for Secure Search and other Algorithms) is a workshop organized every few years to discuss the advances in Searchable Encryption (SE). This third edition (like the previous two editions) was organized in Bertinoro (Italy) by Sasha Boldyreva and Adam O\u0026rsquo;Neill. Thanks to one of my PhD advisors, I received an invite and was able to attend this event.\nDue to various reasons (primarily the COVID pandemic), I never had the opportunity to present my previous papers physically. Hence, I hadn\u0026rsquo;t met anyone from the SE community. Hence, it was the perfect occasion to get to know the community. Moreover, we even had new results to present, so the timing was ideal.\nFirst and foremost, I want to thank Sacha and Adam for the organization. I enjoyed this event so much. I consider this kind of event to be more fruitful than any top-tier conference to build collaborations and plant the seeds of future scientific breakthroughs.\nThe venue The workshop was organized in an old stone building atop a hill. From the venue, we have an astounding view of the Emilia-Romagna region. Unfortunately, the week has been quite rainy, but we had a few sunny breaks to enjoy the view\u0026hellip; and take a group photo!\nThe building is an old castle/monastery. The rooms are a bit austere, but you feel like you are in a spiritual retreat. The conference room even looks like an old chapel with painted walls and ceilings. I really love the atmosphere it gives to the event.\nThe only downside of the venue is its location: Bertinoro is not easy to reach. However, the venue is excellent once there, so it can be worth it. Some researchers only came from the US for this event, so I cannot complain about the travel time. For European researchers attending this event, I suggest taking the train and stopping in Milan or Bologna for one or two nights. In my case, I could not make the whole train travel in a day, so it was a perfect excuse to visit another city on my way to Bertinoro.\nThe community It was great to meet the SE community. We were about 20 participants. Despite the absence of a few major researchers, the event size was nice for having meaningful discussions. The SE community is more or less divided into two blocks: the cryptanalysts (attacking the schemes) and the cryptographers (proposing schemes). This duality helps to develop exciting debates. The attendees were super nice, and I was glad to meet them.\nI often compare various scientific habits since my PhD is at the intersection of several communities (i.e., security, cryptography, privacy, and machine learning). While it is insightful as a PhD student to discover the different ways to build scientific communities, I must appear annoying because I sometimes point out how things can be better in another community ðŸ™ƒ. However, it was not the case in Bertinoro since I praised how the ML community\u0026rsquo;s habits (and size) are problematic compared to the security community\u0026rsquo;s.\nThe talks Surprisingly, I wrote three attack papers, but I had no clue how SE was implemented in practice. The SE design talks were then the occasion to fill my ignorance. On the other hand, I obviously liked the talks presenting novel attacks. These papers are fun to build. Like many security researchers, it is easy to catch my attention with new attack problems. If I had to highlight only one talk, I would mention Tianxin\u0026rsquo;s presentation about MongoDB. It is an essential reminder that real-world deployments require us to be extra careful with the implementation details. Otherwise, all our theoretical efforts will be worthless in the end.\nMy overall takeaway from these talks is that the attack literature has been rather prolific over the last few years. The efforts in SE constructions continued. It is now time to confront these lines of work.\nMy talk You may wonder what I presented during this workshop. This is an excellent question! During ESSA, we want to gather feedback about a new idea called \u0026ldquo;statistical risk assessment\u0026rdquo;. Like many people in the room, we have been part of the attack literature, ten years of successive \u0026ldquo;highly accurate\u0026rdquo; attacks. However, a key question remains after ten years: should we deploy SE? Indeed, these papers (including ours) tell us that some attacks can be effective. However, they do not tell us whether they are problematic in real-world use cases. Our idea is to provide an experimental protocol to decide whether a specific use case is secure or not. The literature already contained the intuition that the attack accuracy is use-case dependent. Hence, we provide a rigorous method to assess the risk.\nThis paper was tricky to write because it is unusual for the security community. Instead of theoretical guarantees/bounds, we propose to rely on statistical guarantees. We gathered positive feedback at ESSA, and I was super happy about it. The paper is still under review, so we are not there yet, but it is a good first sign. This idea has many implications (not only in SE), so I am looking forward to the feedback from the community.\nIf you want to take a look at my slides, you can find them here. A preprint should be available soon, and once the paper is accepted, I will write another post to detail the intuitions behind the paper.\nWhat\u0026rsquo;s next in Searchable Encryption? Since this event aims to shape the future of SE, I think it would be good to give my point of view on the question. I consider it time to implement real-world applications. MongoDB Queryable Encryption is a good first step but a general-purpose library. We need a concrete and public application to advertise the interest of SE. For example, implementing an encrypted search index for a popular messaging application (e.g., Matrix) would fulfill this goal. Such a project would require efforts from both the construction sub-community to provide a scalable and adequate scheme and the attack sub-community to quantify the risks precisely.\nCurrently, SE is somewhat of a side project for me, so I won\u0026rsquo;t be proactive in that direction immediately. However, I would love to be part of such efforts if someone is interested in my takes on statistical risk assessment.\n","permalink":"https://marc.damie.eu/posts/essa3/","summary":"In early June 2023, Searchable Encryption researchers gathered to discuss past and future achievements in this area\u0026hellip;and I was there!","title":"ESSA3, an amazing workshop about Searchable Encryption"},{"content":"Since this post contains some criticism, a preliminary disclaimer is necessary. The conference was well-organised, and I congratulate the chairs for this great event. Social events, food, venue, etc., everything was great. My criticism will be more on what is considered good scientific work in the ML community. This criticism is not limited to ML. I attended an ML conference, so I limit my discussion to the ML community, even if I suppose one can observe similar observations in other communities. Hence, the concerns exposed in this post are not specific to ECML-PKDD or its organisation.\nMoreover, I do not want to seem rude or smug. This post aims at sharing the first (positive and negative) impressions of a naive and young PhD student at an ML conference. See this post more as the first page of my research life diary rather than as a structured criticism of scientific practices.\nDiscovering a scientific conference with fresh eyes ðŸ¤“ ECML-PKDD 2022 was my first in-person conference. So I didn\u0026rsquo;t know what to expect. Some of my colleagues told me about conferences they went to, such as ICML, but I knew ECML-PKDD was smaller. So it was hard to picture exactly how it would feel to be at a scientific conference. At first, I was a bit amazed that such an enormous scientific event happened while the general public ignored their existence.\nSpecialized conference but already so many unknown topics As a PhD student, I was overwhelmed by the program. So many topics, so many papers, and among them, very few that I can fully understand. It was a humbling experience to see how limited my knowledge is. I used this as an opportunity to get first intuitions about many unknown concepts. When I started my research work, I always wanted a perfect understanding of everything I read. I spent days on some articles to grasp all the details. With this kind of event, I learn to look for general insights and leave the details for later. Considering how rich scientific literature is, I cannot afford the price of exhaustiveness.\nFor example, I don\u0026rsquo;t work on concept drift in ML (concept drift defines a change in the distribution between the training data and real-world data). When I listen to a talk about concept drift, I don\u0026rsquo;t even want the details because I already ignore the state-of-the-art. I expect the speaker to explain why this paper changed the landscape of concept drift but not precisely how. I want a before/after photo, like for a haircut but for a scientific object. I want to understand why this new haircut (state of the art in the case of scientific objects) is different and avoid all the hair-cutting process. Maybe someday, I\u0026rsquo;ll work on concept drift and having concise conclusions I can remember is crucial so I have a starting point when this day happens. I should keep the discovery details for the day I need them because I\u0026rsquo;ll forget them anyway. Finally, these expectations are also in line with the time left to the presenters. A presenter should not even try to give details in a 10-minute presentation. Any attempt would result in a snorkel-like exercise where the speaker doesn\u0026rsquo;t breathe for 10 minutes to expose all elements.\nPoster sessions are kinda cool Before coming to ECML-PKDD, the poster format was not appealing to me. I felt like it was an old habit that researchers maintained as a tradition. I couldn\u0026rsquo;t imagine how wrong I was. Poster sessions are better than anything else to discuss with other researchers. It is way better than slides to encourage interactions.\nMoreover, it forces the presenter to adapt the presentation to her audience. You can\u0026rsquo;t have an already written text that you read (as some speakers do with Powerpoint). As a result, the presentation seems more authentic, and I feel more comfortable asking stupid questions. Indeed, in front of a crowd, you always have an expert asking a super precise and intelligent question. I cannot take the mic after this person and ask a basic and possibly stupid question.\nBrilliant researchers are way too normal Finally, ECML-PKDD was an occasion to see some brilliant researchers such as Francis Bach and Yann Le Cun. I studied in a small French university, so I had fewer opportunities than other (Parisian) students to meet researchers of such world renown. I was a bit disappointed by how normal they seemed. I was expecting quirkier researchers. In the past, I read some stories about the mathematician Norbert Wiener, and I wanted to meet such unique personalities. There are two solutions to this enigma: either ML researchers act normal in public to avoid having funny stories published about them by their peers, or ML has become so mainstream that we lost all sense of quirkiness in the process :clown_face:\nDisillusions ðŸ˜¢ Now, it is the challenging part for me and, possibly, the juicy part for you: it is time for some criticism. I encountered three main issues: over-specialization, (capitalistic) motivations of the papers, publish or perish.\nOver-specialization ðŸ”¬ This first issue is related to my expectations for the presentations. Papers are increasingly specialised; non-expert researchers barely understand most of these papers. I had a similar remark on my first paper, but the problem became real when I attended ECML-PKDD. I saw presentations of ML papers from which I could not draw any conclusions because I could not understand anything. It can then be a beginner mistake.\nI believe this is a more general issue. An ML conference is already a specialised conference, and any participant should be able to understand (at least partially) most presentations. Unfortunately, it is not the case, and it reminded me of a conversation I had during a summer school on sustainable AI in Saarbrucken (Germany). I met a PhD student in philosophy who asked the ML PhD students something like: \u0026ldquo;But you cannot even understand each other research, right?\u0026rdquo; (she said that, in Philosophy, any peer is usually able to give feedback). We somehow answered that we do understand each other to some extent. Unfortunately, she quickly identified a rather sad reality (according to me). Of course, I don\u0026rsquo;t expect any CS student to grasp what we do, but having any ML researcher would already be a satisfying first goal.\nI am working at the edge of several CS fields: security, cryptography, and ML. Over my short career, I have seen researchers only look at the publications of their sub-community at the risk of reinventing the wheel. Over-specialisation is a problem because it makes conference participation less appealing than it could be, but it is also a problem for scientific production! I am probably judging researchers a bit too quickly there. Of course, having a fixed community is also convenient for collaboration and publication, but I still want to emphasise this impression I got.\nCapitalistic motivations of the papers ðŸ’¶ I want to start this paragraph with a simple statement: everything is political, including scientific work. I am one of those researchers irritated by the claim of \u0026ldquo;apolitical work\u0026rdquo;. Unfortunately, I don\u0026rsquo;t have time (and qualifications) to detail this topic, but I suggest reading [1] by L. Wiener, which is a great starting point for this kind of discussion.\nMany papers had motivations that I find quite worrying. At the conference, you can hear all the buzzwords promoted by the industry. Usually, these papers improve an industrial use case. Industrial applications are not fundamentally bad, but they represent a large part of the conference. We have very few papers promoting applications with societal impact. The only effect I foresee for these papers is even more Big Tech companies, more monopolies, etc. For example, several talks on recommender systems explained how to improve Amazon-like recommendation systems. We live in a world where recommender systems create filter bubbles and may promote extremist ideas. Still, the motivation is to improve by 1% Amazon recommendation so they can sell us more unnecessary objects.\nThis point of view might seem a bit harsh, but I am part of a generation that will have to deal with many crises in the future: climate, the rise of far-right influence, etc. I see a lot of public-funded research to contribute to private interest while there are plenty of challenges to overcome nowadays. We should be more careful with our expectations in terms of motivation. These papers are usually applied papers where poor motivations induce poor quality, whatever are the improvements \u0026ldquo;shown\u0026rdquo; in the figures.\nRecently, I read [2] by Rogaway, which detailed such criticism for the cryptography community. Rogaway highlights the role of cryptographers and questions the interests of the current research works. He even identified when a split happened in the crypto community: when the cryptographers started doing cryptography for cryptography instead of cryptography for the people. I think a similar discussion is necessary among AI researchers. We need to define the exact role of ML research in our societies. Yann Le Cun gave a first answer to this question during his keynote: he promoted autonomous intelligence (via self-supervised learning). This idea seems very similar to the dreams that the AI founders may have had. However, I can also criticize this vision and ask whether it truly fits the current challenges of our societies. Some researchers (such as Romain Couillet [3]) are developing a discourse about frugal AI and even question whether a sustainable AI can exist considering modern ML models\u0026rsquo; carbon footprint. Finally, there is also the issue of developing AI for people. Currently, most AI models are only used by big companies to increase profit. Then, I want to add another question: can we use AI to truly improve the average human being daily life? If yes, is it what we are doing?\nPublish or perish: motivations of the researchers ðŸ’€ Now that I have talked about the motivations of the papers, I should talk about the researchers\u0026rsquo; motivations. I am not discovering the publish or perish concept (i.e., the pressure to publish more and more publish to succeed in academic careers). However, I found how researchers behave according to it. Usually, all researchers discussing this concept agree that it is a problem. But, at this conference, it became evident that many of them fully accepted it. I can give a concrete example: I discussed with a PhD student who presented his work vaguely without conviction during a poster session. At the end of our discussion, he even said that he published it because an implicit requirement is to have at least three papers by the end of your PhD. I was astonished by his sentence. I am sure many researchers share this attitude but don\u0026rsquo;t dare say it as explicitly as this student.\nI had the same feeling during a Scientific Writing class where I was part of the minority defending that the first motivation when submitting a paper must always be \u0026ldquo;having results to share with the scientific community\u0026rdquo;. Professional success can only be a positive side effect. To justify that, I tried an analogy with surgery. A surgeon must undergo surgery if and only if it is necessary for the patient. The fact that the surgery may bring money or success to the surgeon should never be a motivation\u0026hellip; at least, that\u0026rsquo;s what I expect from my surgeon.\nI understand that many of us would appreciate a position in academia. However, I don\u0026rsquo;t think we should develop an unhealthy attitude to achieve our personal goals. These researches are funded with public money, and even if the media give little attention to Science, we should be careful in being exemplary. Our profession is still highly respected, and we must maintain this trust. Moreover, we are all researchers in ML, and we cannot argue that we absolutely need a job in academia to live. One can make good money in the industry with an ML degree. I acknowledge that academic research can be a dream job, but we should not support a toxic system to reach this goal.\nConclusion: what about me? After all this criticism, you may want to confront me and ask whether I am a perfect scientist producing excellent scientific work with pure motivation. First, I am nobody in the scientific community: I have two published papers and am early enough in my PhD not to worry about actions I should take to preserve my academic career. Hence, I have no authority, and I accept that one may consider all my thoughts rubbish from a young student who doesn\u0026rsquo;t understand the scientific world. However, my ideas might be interesting because they confront the current scientific practices with a PhD student\u0026rsquo;s naive and ideal expectations.\nUndoubtedly, I will publish over-specialized papers (and already did!), I\u0026rsquo;ll have publications with purely capitalistic motivations, etc. However, I\u0026rsquo;ll also try to have scientific practices that converge as much as possible towards the ideals I had in me on September 19, 2022, when I arrived in ECML-PKDD.\nReferences ðŸ“š Winner, L. (2017). Do artifacts have politics?. In Computer Ethics (pp. 177-192). Routledge. Rogaway, P. (2015). The moral character of cryptographic work. Cryptology ePrint Archive. Couillet, R. et al. (2022). Lâ€™intelligence artificielle peut-elle devenir un outil convivial? Preprint. In French only. ","permalink":"https://marc.damie.eu/posts/ecml-pkdd-22/","summary":"I attended my first in-person conference and wanted to share the perspective of a young doctoral student full of ideals on scientific work.","title":"ECML-PKDD, my first ML conference: between discovery and disillusions"},{"content":"Academic context ðŸ« I created this graph for Franck Ghitalla\u0026rsquo;s network science course. Each edge is a hyperlink and a node is a web entity. To create these graphs, I just needed to realize few simple crawls.\nThanks to this kind of graph, we can visualize and analyse strategies for occupation of web territory. We can also consider social organizations thanks to the web content production.\nI studied the strategy of occupation of several groups : far right, Scientology and Jehovah\u0026rsquo;s Witnesses. I chose to show only the graph about Scientology because I consider it as the most clean and atypical.\nIf you want to learn more about the analysis of Web using graph, I strongly recommend the book Qu\u0026rsquo;est-ce que la cartographie du Web? (written by F. Ghitalla, D. Boullier and M. Jacomy) which compiles Franck\u0026rsquo;s blog posts/publications about this question.\nGraph on Scientology\u0026rsquo;s strategy of web occupation Thanks to the graph above, we see an occupation of Web territory very well thought by the Church of Scientology. To create this graph, I just needed to crawl from scientology.org (with a fixed maximum depth). No data cleaning has been done.\nWeb Version of the graph\nLegend Node : Website/entity Edge : Hyperlink between two entities Colour/Size : node degree Graph analysis The Scientology Web looks like an intranet: there is no outbound link pointing at Mainstream Web like Youtube, etc. The nodes have an extremely high degree : usually for this kind of website sample, the entity with the highest degree is Youtube and isn\u0026rsquo;t pointed by 90% of the websites. There is a very high density which creates this round shape. There are two poles: a religious one (scientology.org, etc.) and a cultural one (Dianetics.org, etc.) The further a website is from the centre, the more local the entity is(Scientologi.se, Scientology-Detroit.org, etc.) There are just few French nodes and their degrees are extremely low. Conclusions Scientology deployed a very cleaver Web occupation. Firstly, we notice the existence of a cultural pole which could be an important entry point to the religious part of Scientology. The idea of not having outbound links in this cluster allows to keep the users in the Scientology Web. The big degrees grant a very good ranking by Google algorithms. Finally, the local entities have low degrees because they present an interest for \u0026ldquo;believers\u0026rdquo; who have a daily use of these websites. They are like the end of the road in the Scientology Web.\nThe low degree of French nodes is a strong argument to explain the small presence of Scientology in France (compared to other countries). Therefore, we notice that Scientology haven\u0026rsquo;t succeeded in deploying their strategy of Web occupation in France yet.\nIt is important to understand that this strategy was a brilliant hack a decade (or even two) ago. The initial Google\u0026rsquo;s Page Rank algorithm uses the notion of node degree to index the website. A web page with a high degree is seen as a very popular page. Hence, such page will have higher chance to be returned by Google when you search for something. Obviously, the Web technologies gained in maturity, and I am sure that modern indexation algorithm have some solutions to prevent these \u0026ldquo;hacks\u0026rdquo;\u0026hellip; especially from such organizations.\nFinally, I want to point out that this graph was done on November 2019. About a decade before that, Frank had followed the exact same procedure to study the strategy of the Church of Scientology. My first intent was to observe the evolution of this strategy. In contrary, we had observed that the strategy hadn\u0026rsquo;t changed over a decade!\nTechnologies ðŸ’» Python (crawler) Gephi Hyphe ","permalink":"https://marc.damie.eu/posts/scientology/","summary":"I analyze the Web territory occupation using graphs and expose the very specific strategy deployed by the Church of Scientology to \u0026ldquo;hack\u0026rdquo; the Page Rank algorithm.","title":"Graph visualization: Scientology Web strategy"},{"content":"Academic context ðŸ« This project had been supervised by StÃ©phane Crozat (Assistant professor at the University of Technology of CompiÃ¨gne) and Antoine Barbare (Engineer at Scaleway). The objective was to create introductory courses for classic courses or one-time trainings.\nResults ðŸ–§ I contributed in several parts of these courses:\nCorrected courses on VM, SSH and nginx. Wrote two courses on PostgreSQL administration: GÃ©rer les connexions et les droits utilisateurs sous PostgreSQL et Sauvegarde et restauration d\u0026rsquo;une base de donnÃ©es sous PostgreSQL Wrote a course on DNS XSL development For more details, you can read this wiki (only in French).\nTechnologies ðŸ’» PHP Nginx Debian PostgreSQL BIND9 XML XSLT ","permalink":"https://marc.damie.eu/posts/network-service-course/","summary":"Academic project to conceive basic courses about system administration.","title":"Introductory courses on system and network administration"},{"content":"On this website, you\u0026rsquo;ll find a bunch of interesting (and non-interesting) information about me. I\u0026rsquo;ll describe my curriculum as well as my current research interests. On the other hand, I\u0026rsquo;ll also try to add new posts regularly. My first posts present a few academic projects I\u0026rsquo;ve done during my engineering diploma.\nMy future posts may concern different topics. Some will announce news about me, such as an accepted paper. Other posts will detail my thoughts about a technical or scientific problem I study. In particular, I will sometimes try to give my gut feelings about some of my scientific contributions. Indeed, academic papers are reserved for concrete facts, but it could be beneficial to provide intuitions or vague ideas about a formal (and hard-to-grasp) publication.\nBesides the engineer I am and the scientist I want to be, I am also an average citizen with his own metaphysical questions and ethical dilemmas. During my engineering diploma, I had the opportunity, thanks to various courses or non-profit associations, to develop some ethical concerns about sustainability, FOSS, technology, politics, etc. I don\u0026rsquo;t exclude the possibility of writing blog posts about such questions.\nTo conclude, if you want to discuss my work or anything else, feel free to contact me!\n","permalink":"https://marc.damie.eu/posts/welcome/","summary":"This is a small post to introduce you to my blog.","title":"Welcome to my blog!"},{"content":"\u003c!DOCTYPE html\u003e Graph Visualization More about this visualisation Legend: Search: Group Selector: Select Group Return to the full network\tInformation Pane Connections: OII JISC\t","permalink":"https://marc.damie.eu/scientology-graph/","summary":"\u003c!DOCTYPE html\u003e\n\u003chtml xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en-gb\" lang=\"en\" xmlns:og=\"http://opengraphprotocol.org/schema/\" xmlns:fb=\"http://www.facebook.com/2008/fbml\" itemscope itemtype=\"http://schema.org/Map\"\u003e\n\n\u003chead\u003e\n\u003ctitle\u003eGraph Visualization\u003c/title\u003e\n\u003cmeta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta name=\"viewport\" content=\"width=device-width,height=device-height,initial-scale=1,user-scalable=no\" /\u003e\n\u003cmeta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" /\u003e\n\n\n\u003c!--[if IE]\u003e\u003cscript type=\"text/javascript\" src=\"js/excanvas.js\"\u003e\u003c/script\u003e\u003c![endif]--\u003e \u003c!-- js/default.js --\u003e\n  \u003cscript src=\"js/jquery/jquery.min.js\" type=\"text/javascript\"\u003e\u003c/script\u003e\n  \u003cscript src=\"js/sigma/sigma.min.js\" type=\"text/javascript\" language=\"javascript\"\u003e\u003c/script\u003e\n    \u003cscript src=\"js/sigma/sigma.parseJson.js\" type=\"text/javascript\" language=\"javascript\"\u003e\u003c/script\u003e\n  \u003cscript src=\"js/fancybox/jquery.fancybox.pack.js\" type=\"text/javascript\" language=\"javascript\"\u003e\u003c/script\u003e\n  \u003cscript src=\"js/main.js\" type=\"text/javascript\" language=\"javascript\"\u003e\u003c/script\u003e\n\n  \u003clink rel=\"shortcut icon\" type=\"image/x-icon\" href=\"graph_icon.png\" /\u003e\n  \u003clink rel=\"stylesheet\" type=\"text/css\" href=\"js/fancybox/jquery.fancybox.css\"/\u003e\n  \u003clink rel=\"stylesheet\" href=\"css/style.css\" type=\"text/css\" media=\"screen\" /\u003e\n  \u003clink rel=\"stylesheet\" media=\"screen and (max-height: 770px)\" href=\"css/tablet.css\" /\u003e\n\u003c/head\u003e\n\n\n\u003cbody\u003e\n  \u003cdiv class=\"sigma-parent\"\u003e\n    \u003cdiv class=\"sigma-expand\" id=\"sigma-canvas\"\u003e\u003c/div\u003e\n  \u003c/div\u003e\n\u003cdiv id=\"mainpanel\"\u003e\n  \u003cdiv class=\"col\"\u003e\n\t\t\u003cdiv id=\"maintitle\"\u003e\u003c/div\u003e\n    \u003cdiv id=\"title\"\u003e\u003c/div\u003e\n    \u003cdiv id=\"titletext\"\u003e\u003c/div\u003e\n    \u003cdiv class=\"info cf\"\u003e\n      \u003cdl\u003e\n        \u003cdt class=\"moreinformation\"\u003e\u003c/dt\u003e\n        \u003cdd class=\"line\"\u003e\u003ca href=\"#information\" class=\"line fb\"\u003eMore about this visualisation\u003c/a\u003e\u003c/dd\u003e\n      \u003c/dl\u003e\n    \u003c/div\u003e\n\u003cdiv id=\"legend\"\u003e\n\t\u003cdiv class=\"box\"\u003e\n\t\t\u003ch2\u003eLegend:\u003c/h2\u003e\n\t\t\u003cdl\u003e\n\t\t\u003cdt class=\"node\"\u003e\u003c/dt\u003e\n\t\t\u003cdd\u003e\u003c/dd\u003e\n\t\t\u003cdt class=\"edge\"\u003e\u003c/dt\u003e\n\t\t\u003cdd\u003e\u003c/dd\u003e\n\t\t\u003cdt class=\"colours\"\u003e\u003c/dt\u003e\n\t\t\u003cdd\u003e\u003c/dd\u003e\t\t\n\t\t\u003c/dl\u003e\n\t\u003c/div\u003e\n\u003c/div\u003e \n    \u003cdiv class=\"b1\"\u003e\n    \u003cform\u003e\n      \u003cdiv id=\"search\" class=\"cf\"\u003e\u003ch2\u003eSearch:\u003c/h2\u003e\n        \u003cinput type=\"text\" name=\"search\" value=\"Search by name\" class=\"empty\"/\u003e\u003cdiv class=\"state\"\u003e\u003c/div\u003e\n        \u003cdiv class=\"results\"\u003e\u003c/div\u003e\n      \u003c/div\u003e\n      \u003cdiv class=\"cf\" id=\"attributeselect\"\u003e\u003ch2\u003eGroup Selector:\u003c/h2\u003e\n        \u003cdiv class=\"select\"\u003eSelect Group\u003c/div\u003e\n\t\u003cdiv class=\"list cf\"\u003e\u003c/div\u003e\n      \u003c/div\u003e\n    \u003c/form\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n  \u003cdiv id=\"information\"\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n\t\u003cdiv id=\"zoom\"\u003e\n  \t\t\u003cdiv class=\"z\" rel=\"in\"\u003e\u003c/div\u003e \u003cdiv class=\"z\" rel=\"out\"\u003e\u003c/div\u003e \u003cdiv class=\"z\" rel=\"center\"\u003e\u003c/div\u003e\n\t\u003c/div\u003e\n\t\u003cdiv id=\"copyright\"\u003e\n\t\t\u003ca rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/3.0/\"\u003e\u003cimg alt=\"Creative Commons License\" style=\"border-width:0\" src=\"images/CC.png\" /\u003e\u003c/a\u003e\u003c/div\u003e\n\t\u003c/div\u003e\n\u003cdiv id=\"attributepane\"\u003e\n\u003cdiv class=\"text\"\u003e\n\t\u003cdiv title=\"Close\" class=\"left-close returntext\"\u003e\u003cdiv class=\"c cf\"\u003e\u003cspan\u003eReturn to the full network\u003c/span\u003e\u003c/div\u003e\u003c/div\u003e\t\n\u003cdiv class=\"headertext\"\u003e\n\t\u003cspan\u003eInformation Pane\u003c/span\u003e\n\u003c/div\u003e\t\n  \u003cdiv class=\"nodeattributes\"\u003e\n    \u003cdiv class=\"name\"\u003e\u003c/div\u003e\n\t\u003cdiv class=\"data\"\u003e\u003c/div\u003e\n    \u003cdiv class=\"p\"\u003eConnections:\u003c/div\u003e\n    \u003cdiv class=\"link\"\u003e\n      \u003cul\u003e\n      \u003c/ul\u003e\n    \u003c/div\u003e\n  \u003c/div\u003e\n\t\u003c/div\u003e\n\u003c/div\u003e\n\u003cdiv id=\"developercontainer\"\u003e\n\t\u003ca href=\"http://www.oii.ox.ac.uk\" title=\"Oxford Internet Institute\"\u003e\u003cdiv id=\"oii\"\u003e\u003cspan\u003eOII\u003c/span\u003e\u003c/div\u003e\u003c/a\u003e\n\t\u003ca href=\"http://jisc.ac.uk\" title=\"JISC\"\u003e\u003cdiv id=\"jisc\"\u003e\u003cspan\u003eJISC\u003c/span\u003e\u003c/div\u003e\u003c/a\u003e\t\n\u003c/div\u003e\n\u003cscript type=\"text/javascript\"\u003e\n\n  var _gaq = _gaq || [];\n  _gaq.push(['_setAccount', 'UA-21293169-4']);\n  _gaq.push(['_setDomainName', 'none']);\n  _gaq.push(['_setAllowLinker', true]);\n  _gaq.push(['_trackPageview']);\n\n  (function() {\n    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\n    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\n    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n  })();\n\n\u003c/script\u003e\n\u003c/body\u003e\n\u003c/html\u003e","title":""},{"content":"Short Bio ðŸ“• I am a freshly graduated Computer engineer ðŸŽ“ interested in Cybersecurity and Data. I am currently a PhD student in privacy-preserving machine learning at the University of Twente ðŸ‡³ðŸ‡± and Inria Lille ðŸ‡«ðŸ‡·. I am a geeky person ðŸ¤“ able to discuss in vain any new hype technology. But, on a more personal aspect, I am trying to figure out the place (and the sense) of computer systems in a sustainable world ðŸŒ.\nIf you are interested in my work (or my thoughts), please message me to discuss it!\nA few (anecdotal) facts about me ðŸ“š Interests ðŸ§™ eSport ðŸŽ® CTF ðŸ§‘â€ðŸ’» Drinks ðŸ» with interesting people Language skills ðŸŒ French: Native English: C1 Spanish: B2 Basics of Dutch, Russian, and Chinese Volunteering in non-profit organizations ðŸš€ [February 2018 - September 2021] Member then Treasurer of Rhizome: a non-profit Internet Service Provider Provides events, like Imaginarium Festival, with WiFi used for contactless payment Provides our subscribers with internet access Organizes conferences about open-source and Free-culture movement [2017 - 2018] Manager of Communication and Sponsorships of TEDxUTCompiÃ¨gne Organization of the third TEDxUTCompiÃ¨gne conference [2019] IT Manager of Escap\u0026rsquo;UT (student association building escape rooms in the university) Technical skills ðŸ’» Expert: Python, Django, Flask, LaTeX, Redis Advanced: C/C++, ElasticSearch, Docker, SQL, JavaScript/Typescript Intermediate: R, Scylla, MongoDB Other technologies I used/learned: Rust, XML, XSLT, Scilab, UML, php, Bash, HTML/CSS, etc. ","permalink":"https://marc.damie.eu/about/","summary":"About Marc DAMIE. The short story of my life.","title":"About me"},{"content":"Current status ðŸ« In October 2021, I started a PhD in Federated Learning between Inria Lille and the University of Twente. I am supervised by Jan Ramon (Inria Lille), Florian Hahn (UTwente) and Andreas Peter (UTwente/University of Oldenburg).\nThe goal of my thesis is to provide highly scalable and secure solutions for Federated Learning with a particular focus on resource-constrained devices (e.g. smartphones).\nResearch Interests ðŸ”¬ I have two main research interests are:\nFederated Learning, especially its security aspect. Hence, I read papers about SMPC, Homomorphic Encryption, Function Secret Sharing, etc. My intent isn\u0026rsquo;t to build highly complex ML systems but simply to propose generic secure building blocks for them. Searchable Encryption. This is a subject on which I worked during a previous research internship with Florian Hahn and Andreas Peter. I still have some results and ideas that will result in occasional publications on this subject. More generally, my overall interest is in the privacy-preserving use of data.\nBesides these technical interests, I am open to many other topics. Especially, I am looking forward to any insights on ethics or environmental evaluation of computer systems. These elements essentially contribute to my personal reflections about my long-term role as a computer scientist in world facing multiple crisis.\nPublications ðŸ“ M. Damie, J.-B. Leger, F. Hahn and A. Peter, \u0026lsquo;The statistical nature of leakage in SSE schemes and its role in passive attacks\u0026rsquo;, 2023 (Preprint) M. Dijsklag, M. Damie, F. Hahn and A. Peter, \u0026lsquo;Passive query-recovery attack against secure conjunctive keyword search schemes\u0026rsquo;, ACNS 2022 (B) M. Damie, F. Hahn, and A. Peter, â€˜A Highly Accurate Query-Recovery Attack against Searchable Encryption using Non-Indexed Documentsâ€™, USENIX Security 21 (A*) Awards ðŸ† Nomination for the Dutch CyberSecurity Research Paper (i.e. top 3) with the paper â€˜A Highly Accurate Query-Recovery Attack against Searchable Encryption using Non-Indexed Documentsâ€™ Service Sub-reviews: CCS 2024, PETS 2023, CODASPY 2022 Program committee: NDSS Artifact Evaluation 20{24,25}, PETS Artifact Evaluation 20{24,25}, USENIX Security Poster (2024) Student representative at the University of Technology of CompiÃ¨gne: Board of directors (2017-2021), CS department (2018-2019), Humanities department (2017-2019) ","permalink":"https://marc.damie.eu/research/","summary":"Me, my research and I.","title":"Me, my research and I."}]